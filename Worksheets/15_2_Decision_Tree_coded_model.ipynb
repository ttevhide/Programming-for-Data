{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "15.2 Decision-Tree-coded-model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ttevhide/Programming-for-Data/blob/main/Worksheets/15_2_Decision_Tree_coded_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HyLZK84N75s"
      },
      "source": [
        "# Coding a simple decision tree\n",
        "---\n",
        "\n",
        "In this worksheet we are going to work with a data set, using the idea of a decision tree class.  We are going to simplify the model and use Python code to make a simple decision tree classification model.  We will do this for two reasons:\n",
        "*   writing the code is often good for helping to understand what is going on under the bonnet of a library function\n",
        "*   it is a good coding exercise for practice as it mostly depends on calculations and if..elif..else statements\n",
        "\n",
        "In this worksheet we are going to code a decision tree which will use the calculated probabilities to make decisions about whether a row of given data would be classified as Iris-virginica, or not, based on sepal and petal dimensions.  It is easier to classify between two values (Iris-virginica or not).  Later, using this information, species would be further predicted by probabilities of error.\n",
        "\n",
        "![Iris-petals and sepals](https://www.math.umd.edu/~petersd/666/html/iris_with_labels.jpg)\n",
        "\n",
        "The workflow is:\n",
        "*  divide the data set into 70% of the rows for training and 30% for testing  (we can increase the size of the training set later)\n",
        "*  find the mean for each of the 4 size columns\n",
        "*  calculate the proportion of each column that are on or above mean that are of a species (ie proportion of petal-lengths on or above mean that are Iris-virginica)\n",
        "*  infer the proportion of each that are not of that species (using 1 - proportion above).  In both cases we are looking to find if either of these is 1, which could be infered as definitely not that species. \n",
        "*  calculate a Gini Index that will indicate the probability that a prediction will be incorrect\n",
        "*  use the results of the Gini Index to model a decision tree\n",
        "*  code the decision tree model into a function that will return whether or not a row in the test set is predicted to be of species Iris-virginica\n",
        "*  use the decision tree function to predict, for each row in the test set, if the species will be Iris-virginicia or not, using a set of nested if statements to classify\n",
        "*  compare the predicted values against the actual values in the test set - what proportion were predicted correctly?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iR8g8h_Ol0j"
      },
      "source": [
        "### Exercise 1 - investigate the iris data set\n",
        "---\n",
        "Let's start by looking at the data.  We are going to use a data set that contains data on iris flowers.\n",
        "\n",
        "Read the data at this location: https://raw.githubusercontent.com/jbrownlee/Datasets/master/iris.csv into a dataframe called iris_data\n",
        "\n",
        "The columns in the CSV file do not have headings, when you read the file, add column headings like this:\n",
        "```\n",
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/iris.csv\"\n",
        "names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'species']\n",
        "iris_data = pd.read_csv(url, name=names)\n",
        "```\n",
        "*  Take a look at the column info (how many columns, what type of data, any missing data?)\n",
        "*  Take a look at the data values in the first 10 and the last 10 records to get an idea of the type of values included\n",
        "*  Find out how many unique values there are in the species column\n",
        "*  Find out the maximum, minimum, mean, median and upper and lower quartile values in each of the columns\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGZuOLPYPgL5"
      },
      "source": [
        "import pandas as pd\n",
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/iris.csv\"\n",
        "names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'species']\n",
        "iris_data = pd.read_csv(url, names=names)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0b8Pm0bK_Ca1"
      },
      "source": [
        "### Exercise 2 - split the data into train and test sets\n",
        "---\n",
        "\n",
        "Split the data set into and 70% train, 30% test, split.  From now, just use the train data set.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSG-ZEPEawMJ"
      },
      "source": [
        "# import the train_test_split function\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# create the classification variables from the all columns\n",
        "train, test = train_test_split(iris_data, test_size=0.20)\n",
        "train.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nd-9JfKbQl-q"
      },
      "source": [
        "### Exercise 3 - assumptions and classification\n",
        "---\n",
        "\n",
        "Let's make some assumptions based on the data\n",
        "\n",
        "1.  Iris-setosa, Iris-versicolor, Iris-virginica are the full range of types of iris to be analysed\n",
        "2.  Although this is a small data set, the means are fairly representative\n",
        "\n",
        "With these in mind, let's start by classifying sepal/petal size into long/short and wide/narrow with values on or above the mean taken as long or wide and those below as short or narrow.\n",
        "\n",
        "This is a starting point.  We will be trying to find a value (indicator) for each column where rows on or above do not contain any of a particular species, this might indicate that this column is a good (if not rough) indicator of species.  For now, the indicator is the mean.\n",
        "\n",
        "*  Drop any null values from each column\n",
        "\n",
        "Calculate, and store the means of the four columns\n",
        "\n",
        "*  **Test**:\n",
        "Display train.describe() to see the value of the means of the training set. Print the four means and compare to the output of train.describe() to check that they have been calculated correctly.\n",
        "\n",
        "*  Create a new dataframe with the numeric columns encoded so show a 1 for any value that is above the mean for its column and 0 for any that isn't.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAahb5HSWiw-"
      },
      "source": [
        "# get the mean for each column and apply a function to encode into 1 (above mean) and 0 (mean or below mean)\n",
        "\n",
        "\n",
        "\n",
        "# run the function for each column so that each of the four columns are encoded, then drop the original columns, saving as a new dataframe\n",
        "train['sepal-length'] = train.apply(encode, axis=1, key='sepal-length', indicator=train['sepal-length'].mean())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9lP8lC1dCsa"
      },
      "source": [
        "### Exercise 4 - Calculate the proportion of values on or above the mean that are of each species\n",
        "\n",
        "We are going to focus on the `Iris-virginica` species first.\n",
        "\n",
        "First we will calculate, for each dimension column (`sepal-length, sepal-width, petal-length, petal-width`) what proportion of values in that column, where the value is on or above the mean, are classified as `Iris-virginica`.\n",
        "\n",
        "We will do this by filtering all the records in each column of the the `train` set that are on or above the mean and match the species .  Then use the outcome to calculate the proportion of the full `train` set for which a value on or above the mean that are of species `Iris-virginica`.\n",
        "\n",
        "*  filter for values in the `sepal-length` column being on or above the mean and the species column being `Iris-virginica`.  Then divide the count of rows in this filtered dataset by the count of rows in a second data set, filtered for just the value being on or above the mean.\n",
        "\n",
        "*  Do this for all four columns, for `Iris-virginica`  (4 operations).\n",
        "\n",
        "Print the results to see which columns look like they might most reliably predict the species as `Iris-virginica` (the result is as close as possible to 1).  The highest numbers may indicate the most reliable indicators, but we will do some more before coming to this conclusion.\n",
        "\n",
        "*  By definition, those on or above the mean that are NOT Iris_virginica will be `1 - the proportion of those that are.  Calculate these\n",
        "\n",
        "The first one has been done for you.\n",
        "\n",
        "*  We will also need the proportion of those BELOW the mean that are NOT Iris-virginica.  Calculate these in the same way\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9mzsFwbyruW"
      },
      "source": [
        "# calculate the proportion of results where the value is on or above mean that are of the species Iris-virginica\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-HgetRIxJpx"
      },
      "source": [
        "### Exercise 5 - Calculate the proportion of each column, where the value is below mean, that are of species `Iris-virginica`\n",
        "\n",
        "Repeat the code above, this time looking for values below the mean"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMvl5HFuxpwS"
      },
      "source": [
        "# calculate the proportion of results where the value is below mean that are of the species Iris-virginica\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09zWalzsOZrt"
      },
      "source": [
        "### Exercise 5 - calculate for the other two Iris species\n",
        "---\n",
        "\n",
        "Do the same calculations for the Iris-versicolor species, then for the Iris-setosa species.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYL8B3HhmKAy"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ix6Hh0Uy9MS"
      },
      "source": [
        "### Exercise 6 - predict from the results\n",
        "---\n",
        "\n",
        "Create a list of dictionaries from the results Exercise 4 and 5 (e.g. {'species':..., 'above_mean': 0.xx, 'below_mean': 0.xx}  \n",
        "\n",
        "Then use a loop to go through the list and print:  \n",
        "*  any species and indicator (above or below mean) that can reliably be predicted.  A reliable prediction may be one over 0.5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPvXa8x81re7"
      },
      "source": [
        "# show which columns are reliable predictors\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ws2TxeRrnIJ4"
      },
      "source": [
        "### Exercise 6 - Make a decision tree\n",
        "---\n",
        "\n",
        "Use pencil and paper or a graphical application to create a decision tree for Iris-virginica, using the following rules (use the picture below as a guide):\n",
        "\n",
        "*  The column with the highest indicator is placed at the top\n",
        "*  Other columns are placed in order below\n",
        "*  The rest of the columns are placed in order below these\n",
        "\n",
        "Any column where one branch (on or above mean OR below mean) has an indicator of 0, could be classified as a strong indicator of Iris_virginica being the species.  Anything else, unless there is something very close to 0, could be classified as a weak indicator of Iris_virginica being the species.\n",
        "\n",
        "Let's code the decision tree using the following logic for this decision tree (yours might be slightly different):\n",
        "\n",
        "![Decision tree](https://drive.google.com/uc?id=1CTo23EHwR2IPCRjcfSyCQsT_oQ5Exwso)\n",
        "\n",
        "In the decision tree above, there is no certainty below petal-length so our decision tree will only include petal-width and petal-length.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkCCL0ERDife"
      },
      "source": [
        "def get_species(df):\n",
        "  # ADD CODE HERE TO RETURN None if petal-width is below mean (encoded as 0) or if petal-length is below mean (encoded as 0), otherwise return 'Iris-virginia'\n",
        "\n",
        "\n",
        "# use the get_species(df) function to predict the species, count how many are predicted correct and use this to calculate the proportion correct\n",
        "correct = 0\n",
        "test_size = test.shape[0]\n",
        "for i in range(0, test_size):\n",
        "  species = get_species(test.iloc[i])\n",
        "  if species == test.iloc[i]['species']:\n",
        "      correct += 1\n",
        "\n",
        "print (\"Proportion correctly identified\", correct / test_size) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2tQcT5ILtxl"
      },
      "source": [
        "### Exercise 7 - change the measure\n",
        "\n",
        "We are currently using the mean to act as the decision making line.  We can use the decision tree with a different line.\n",
        "\n",
        "Change the mean values so that you are instead using the median instead for all four columns.  The code should not need changing except for where you calculated the mean.\n",
        "\n",
        "Run all the code again.  Is the proportion of correct values better this time?   Is the decision tree still appropriate?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WimD4E5zNub1"
      },
      "source": [
        "What do you notice? (write your answer here)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WoHQeYLNyk8"
      },
      "source": [
        "### Exercise 8 - try different measures\n",
        "---\n",
        "\n",
        "Do the same again but with upper quantile, then again with the lower quantile.  Is it making any difference?  Which give the best looking results?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8C69ns9VODh3"
      },
      "source": [
        "### Exercise 9 - try a different species\n",
        "\n",
        "Run the mean test again for the Iris-versicolor species.  Again, try some different decision making lines.\n",
        "\n",
        "What are the results.  Record them in the text cell below:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3oXJbqlOU0P"
      },
      "source": [
        "Write your answers here:  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Co14Ws3gupwP"
      },
      "source": [
        "# New logic introduced in this worksheet:\n",
        "\n",
        "1.  Adding headings to a CSV if none currently exist\n",
        "2.  Splitting a data set into train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hpupKkeezXP"
      },
      "source": [
        "## this type of plot will show the distribution on a chart\n",
        "from plotnine import *\n",
        "ggplot(train, aes(x='petal-length', y='petal-width', color='species')) + geom_point() + geom_vline(train, aes(xintercept=train['petal-length'].mean(), color='species')) + geom_hline(train, aes(yintercept=train['petal-width'].mean(), color='species'))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}